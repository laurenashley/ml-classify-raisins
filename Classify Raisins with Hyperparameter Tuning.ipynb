{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cdab51",
   "metadata": {},
   "source": [
    "Regularization and Hyperparamter Tuning Project via Codecademy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f2c52",
   "metadata": {},
   "source": [
    "1. Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Dataset is posted at https://www.kaggle.com/datasets/muratkokludataset/raisin-dataset?resource=download\n",
    "raisins = pd.read_csv('Raisin_Dataset.csv')\n",
    "raisins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create predictor and target variables, X and y\n",
    "X = raisins.drop(columns=['Class'])\n",
    "y = raisins['Class']\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Examine the dataset\n",
    "print('Number of features: ', len(X.columns)-1)\n",
    "print('Number of samples: ', len(X))\n",
    "print('Samples belonging to class \"1\": ', raisins[raisins['Class'] == 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807deac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split the data set into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=19) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcf2d69",
   "metadata": {},
   "source": [
    "2. Grid Search with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa10092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a Decision Tree model\n",
    "tree = DecisionTreeClassifier(random_state=19)\n",
    "\n",
    "# 6. Dictionary of parameters for GridSearchCV\n",
    "parameters = {'max_depth': [3,5,7], 'min_samples_split': [2,3,4]}\n",
    "\n",
    "# 7. Create a GridSearchCV model\n",
    "grid = GridSearchCV(tree, parameters, cv=5)\n",
    "\n",
    "#Fit the GridSearchCV model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 8. Print the model and hyperparameters obtained by GridSearchCV\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Print best score\n",
    "print(grid.best_score_)\n",
    "# Print the accuracy of the final model on the test data\n",
    "print(grid.score(X_test, y_test))\n",
    "\n",
    "# 9. Print a table summarizing the results of GridSearchCV\n",
    "print(pd.DataFrame(grid.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa3a04",
   "metadata": {},
   "source": [
    "2. Random Search with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf85a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. The logistic regression model\n",
    "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# 11. Define distributions to choose hyperparameters from\n",
    "distributions = {'penalty': ['l1','l2'], 'C': uniform(loc=0, scale=100)}\n",
    "\n",
    "# 12. Create a RandomizedSearchCV model\n",
    "clf = RandomizedSearchCV(lr, distributions, n_iter=8)\n",
    "\n",
    "# Fit the random search model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 13. Print best esimatore and best score\n",
    "print(clf.best_params_)\n",
    "# print(clf.best_score_)\n",
    "\n",
    "#Print a table summarizing the results of RandomSearchCV\n",
    "df = pd.concat([pd.DataFrame(clf.cv_results_['params']), pd.DataFrame(clf.cv_results_['mean_test_score'], columns=['Accuracy'])] ,axis=1)\n",
    "print(df.sort_values('Accuracy', ascending = False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ce8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fad9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c15ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
